import os
import json
import streamlit as st
import google.generativeai as genai

# Configura√ß√£o da chave da API do Gemini
working_dir = os.path.dirname(os.path.abspath(__file__))
config_data = json.load(open(f"{working_dir}/config.json"))
GEMINI_API_KEY = config_data["GEMINI_API_KEY"]

genai.configure(api_key=GEMINI_API_KEY)  # Configura a API do Gemini

# Configura√ß√£o do Streamlit
st.set_page_config(
    page_title="ChatBot Dark Souls",
    page_icon="‚öúÔ∏è",
    layout="centered",
)

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Tema Dark Souls - Prompt de Instru√ß√£o
prompt_sistema = """
Voc√™ √© um especialista no jogo Dark Souls e sabe tudo sobre a lore, personagens, estrat√©gias, mapas, e segredos do jogo. 
Responda √†s perguntas de maneira precisa e dentro do contexto do universo de Dark Souls.
Quando algu√©m perguntar sobre o jogo, forne√ßa detalhes e dicas relevantes, sempre mantendo o estilo e a atmosfera sombria e misteriosa do jogo.
"""

st.title("üî• ChatBot Dark Souls")

st.markdown("""
**Bem-vindo ao ChatBot Dark Souls!**

Sou um especialista no universo de **Dark Souls**, um jogo desafiador e repleto de mist√©rios. 
Aqui, voc√™ pode me perguntar tudo sobre a lore, personagens, armas, estrat√©gias de combate e segredos escondidos.
Meu objetivo √© gui√°-lo nesse mundo sombrio e complexo, oferecendo dicas e informa√ß√µes valiosas sobre o jogo.
Quando voc√™ estiver pronto, basta digitar sua pergunta e eu responderei com o m√°ximo de detalhes que eu souber!
""")

for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

user_prompt = st.chat_input("Fale com o ChatBot sobre Dark Souls...")

if user_prompt:
    st.chat_message("user").markdown(user_prompt)
    st.session_state.chat_history.append({"role": "user", "content": user_prompt})

    # Combina o prompt do sistema com o prompt do usu√°rio
    combined_prompt = prompt_sistema + "\n" + "Pergunta do usu√°rio: " + user_prompt

    model = genai.GenerativeModel("models/gemini-1.5-pro")  # Escolhe o modelo do Gemini
    response = model.generate_content(combined_prompt)  # Passa o prompt combinado

    assistant_response = response.text  # Obt√©m a resposta do Gemini
    st.session_state.chat_history.append({"role": "assistant", "content": assistant_response})

    with st.chat_message("assistant"):
        st.markdown(assistant_response)
